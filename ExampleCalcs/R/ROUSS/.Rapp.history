ss <- tt[2:qp1] - tt[1:q]
t.cols     <- matrix(rep(tt,each=qp1),nrow=qp1,ncol=qp1, byrow=FALSE);
t.rows     <- t(t.cols);
t.cols
t.rows
abs.diffs  <- abs(t.rows-t.cols)
abs.diffs
?min
pmin(t.rows,t.cols)
out <- matri(0,nrow=qp1, ncol=qp1)
out <- matrix(0,nrow=qp1, ncol=qp1)
min(2,4)
out <- matrix(0,nrow=qp1, ncol=qp1)#
for( in in 1:qp1){#
	for(j in i:qp1){#
		out[i,j] <- min(t.rows[i,j], t.cols[i,j])#
	}#
}
out <- matrix(0,nrow=qp1, ncol=qp1)#
for(i in 1:qp1){#
	for(j in i:qp1){#
		out[i,j] <- min(t.rows[i,j], t.cols[i,j])#
	}#
}
out
out <- matrix(0,nrow=qp1, ncol=qp1)#
for(i in 1:qp1){#
	for(j in 1:qp1){#
		out[i,j] <- min(t.rows[i,j], t.cols[i,j])#
	}#
}
out
t.cols
t.rows
tis <- t.rows[,1]
tis
negloglike.OU.ml2 <- function(fguess,yt,tt,statio=1){#
	# if statio=1, then use the stationary likelihood. else if statio = 0, use the nonstationary case#
	if(statio==1){#
		mu <- fguess[1];#
		guess  <- exp(fguess[2:4]); # Constrains parameters > 0#
		theta  <- guess[1]; #
		betasq <- guess[2];#
		tausq  <- guess[3];#
		q      <- length(yt) - 1;#
		qp1    <- q+1;#
		Var.inf<- betasq/(2*theta); # Better than Dr. Seuss' thing 1 and thing 2!#
		ss <- tt[2:qp1] - tt[1:q];#
		t.cols     <- matrix(rep(tt,each=qp1),nrow=qp1,ncol=qp1, byrow=FALSE);#
		t.rows     <- t(t.cols);#
		abs.diffs  <- abs(t.rows-t.cols);#
		V          <- Var.inf*exp(-theta*abs.diffs);#
		diag(V)    <- diag(V) + rep(tausq,qp1);#
		mu.vec     <- rep(mu,qp1);#
		neglogl <- (qp1/2)*log(2*pi)+(1/2)*log(det(V))+ (1/2)*(yt-mu.vec)%*%ginv(V)%*%(yt-mu.vec);#
	}else if(statio==0){#
		mu <- fguess[1];#
		guess  <- exp(fguess[2:5]); # Constrains parameters > 0#
		theta  <- guess[1]; #
		betasq <- guess[2];#
		tausq  <- guess[3];#
		xo     <- guess[4];	#
		q      <- length(yt) - 1;#
		qp1    <- q+1;#
		Var.inf<- betasq/(2*theta); # Better than Dr. Seuss' thing 1 and thing 2!#
		ss <- tt[2:qp1] - tt[1:q];#
		t.cols     <- matrix(rep(tt,each=qp1),nrow=qp1,ncol=qp1, byrow=FALSE);#
		t.rows     <- t(t.cols);#
		abs.diffs  <- abs(t.rows-t.cols);#
		min.titj   <- pmin(t.rows,t.cols); #elementwise minima between two matrices#
		V          <- Var.inf*(1-exp(-2*theta*min.titj))*exp(-theta*abs.diffs);#
		diag(V)    <- diag(V) + rep(tausq,qp1);#
		mu.vec     <- rep(mu,qp1) - (mu-xo)*exp(-theta*tt);#
		neglogl    <- (qp1/2)*log(2*pi)+(1/2)*log(det(V))+ (1/2)*(yt-mu.vec)%*%ginv(V)%*%(yt-mu.vec);#
	}#
	return(neglogl)#
}
ROUSS.ML2 <- function(Yobs,Tvec, parms.guess,statio=0){#
	tt  <- Tvec-Tvec[1];#
	q   <- length(tt) -1; #
	qp1 <- q+1;#
	if(statio==1){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4])) #
		optim.out <- optim(par=guess.optim,fn=negloglike.OU.ml,method="Nelder-Mead",yt=Yobs,tt=tt)#
		mles <- c(optim.out$par[1], exp(optim.out$par[2:4]))#
		lnL.hat <- - optim.out$value[1]#
		AIC     <- -2*lnL.hat + 2*4 #where 4 = length(mles)... #
	}else if(statio==0){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4]), Yobs[1]);#
		optim.out <- (par=guess.optim, fn=negloglike.OU.ml2, method="Nelder-Mead", yt=Yobs, tt=tt,statio=statio);#
		mles      <- c(optim.out$par[1], exp(optim.out$par[2:5]));#
		lnL.hat   <- - optim.out$value[1]#
		AIC       <- -2*lnL.hat + 2*5 # where 5= length(mles) #
	}#
	out <- list(mles=mles, lnL.hat = lnL.hat, AIC=AIC)#
	return(out)#
}
ROUSS.ML2 <- function(Yobs,Tvec, parms.guess,statio=0){#
	tt  <- Tvec-Tvec[1];#
	q   <- length(tt) -1; #
	qp1 <- q+1;#
	if(statio==1){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4])) #
		optim.out <- optim(par=guess.optim,fn=negloglike.OU.ml,method="Nelder-Mead",yt=Yobs,tt=tt)#
		mles <- c(optim.out$par[1], exp(optim.out$par[2:4]))#
		lnL.hat <- - optim.out$value[1]#
		AIC     <- -2*lnL.hat + 2*4 #where 4 = length(mles)... #
	}else if(statio==0){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4]), Yobs[1]);#
		optim.out <- optim(par=guess.optim, fn=negloglike.OU.ml2, method="Nelder-Mead", yt=Yobs, tt=tt,statio=statio);#
		mles      <- c(optim.out$par[1], exp(optim.out$par[2:5]));#
		lnL.hat   <- - optim.out$value[1]#
		AIC       <- -2*lnL.hat + 2*5 # where 5= length(mles) #
	}#
	out <- list(mles=mles, lnL.hat = lnL.hat, AIC=AIC)#
	return(out)#
}
Host.data
Host.dat
Host.time <- cumsum(c(0,rep(10,length(Host.dat[,1]))))
Host.time
1400/60
Host.time <- cumsum(c(0,rep(10,144)))
Host.time
1440/60
Host.times <- cumsum(c(0,rep(10,length(Host.dat[,1]))))
trial.onets<- Host.dat[,1]
ROUSS.ML2 <- function(Yobs,Tvec, parms.guess,statio=0){#
	tt  <- Tvec-Tvec[1];#
	q   <- length(tt) -1; #
	qp1 <- q+1;#
	if(statio==1){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4])) #
		optim.out <- optim(par=guess.optim,fn=negloglike.OU.ml,method="Nelder-Mead",yt=Yobs,tt=tt)#
		mles <- c(optim.out$par[1], exp(optim.out$par[2:4]))#
		lnL.hat <- - optim.out$value[1]#
		AIC     <- -2*lnL.hat + 2*4 #where 4 = length(mles)... #
	}else if(statio==0){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4]), Yobs[1]);#
		optim.out <- optim(par=guess.optim, fn=negloglike.OU.ml2, method="Nelder-Mead", yt=Yobs, tt=tt,statio=statio);#
		mles      <- c(optim.out$par[1], exp(optim.out$par[2:5]));#
		lnL.hat   <- - optim.out$value[1]#
		AIC       <- -2*lnL.hat + 2*5 # where 5= length(mles) #
	}#
	out <- list(mles=mles, lnL.hat = lnL.hat, AIC=AIC)#
	return(out)#
}
guess.calc <- function(Yobs,Tvec){#
	T.t <-Tvec-Tvec[1]; #  For calculations, time starts at zero.#
	q <- length(Yobs)-1;      #  Number of time series transitions, q.#
	qp1 <- q+1;              #  q+1 gets used a lot, too.#
	S.t <- T.t[2:qp1]-T.t[1:q];  #  Time intervals.#
	Ybar <- mean(Yobs);#
	Yvar <- sum((Yobs-Ybar)*(Yobs-Ybar))/q;#
	mu1 <- Ybar;#
#
	# Kludge an initial value for theta based on mean of Y(t+s) given Y(t).#
	th1<- -mean(log(abs((Yobs[2:qp1]-mu1)/(Yobs[1:q]-mu1)))/S.t);            #
	bsq1<- 2*th1*Yvar/(1+2*th1);         # Moment estimate using stationary#
	tsq1<- bsq1;                         #   variance, with betasq=tausq.#
#
	out <- c(mu1,th1,bsq1,tsq1);#
	return(abs(out))#
}
trial.onets<- log(Host.dat[,1])
trial.onets
guess.one  <- guess.calc(Yobs=trial.onets, Tvec=Host.times)
guess.one
trial.one  <- ROUSS.ML2(Yobs=trial.onets,Tvec=Host.times, parms.guess=guess.one, statio=0)
library(MASS)
trial.one  <- ROUSS.ML2(Yobs=trial.onets,Tvec=Host.times, parms.guess=guess.one, statio=0)
qp1
mu
mu <- 2.48
theta <- 0.0012
betasq <- 0.002652
tausq <- 0.002652
xo <- trial.onets[1]
xo
rep(mu,qp1)
tt
(mu-xo)*exp(-theta*tt)
yt <- trial.onets[,1:10]
yt <- trial.onets[1:10,1]
yt <- Host.dat[1:10,1]
yt
yt <- log(Host.dat[1:10,1])
yt
q      <- length(yt) - 1;#
		qp1    <- q+1;#
		Var.inf<- betasq/(2*theta); # Better than Dr. Seuss' thing 1 and thing 2!
ss <- tt[2:qp1] - tt[1:q];
t.cols     <- matrix(rep(tt,each=qp1),nrow=qp1,ncol=qp1, byrow=FALSE);#
		t.rows     <- t(t.cols);#
		abs.diffs  <- abs(t.rows-t.cols);#
		min.titj   <- pmin(t.rows,t.cols); #elementwise minima between two matrices#
		V          <- Var.inf*(1-exp(-2*theta*min.titj))*exp(-theta*abs.diffs);
diag(V)    <- diag(V) + rep(tausq,qp1);
V
mu.vec     <- rep(mu,qp1) - (mu-xo)*exp(-theta*tt);
mu.vec
(yt-mu.vec)
(yt-mu.vec)%*%ginv(V)
(yt-mu.vec)%*%ginv(V)%*%(yt-mu.vec)
length(trial.onets)
length(Host.times)
Host.times <- cumsum(rep(10,length(Host.dat[,1])) ) - 10;
Host.times
time.interval <- 10 # OD measurements taken every 10 minutes#
Host.times <- cumsum(rep(time.interval,length(Host.dat[,1])) ) - time.interval;
Host.times
length(Host.times)
trial.onets<- log(Host.dat[,1]);#
guess.one  <- guess.calc(Yobs=trial.onets, Tvec=Host.times);
guess.one
trial.one  <- ROUSS.ML2(Yobs=trial.onets,Tvec=Host.times, parms.guess=guess.one, statio=0)
trial.one
joint.negloglike.OU <- function(fguess,Yobs.mat,tt,statio=0){#
	nts <- ncol(Yobs.mat);#
	nllikes <- rep(0,nts);#
		for(i in 1:nts){#
			Yobs <- Yobs.mat[,i]#
			nllikes[i] <- negloglike.OU.ml2(fguess=fguess,yt=Yobs,tt=tt,statio=statio)#
		}#
	return(sum(nnlikes))#
}
JOINT.ROUSS.ML <- function(Yobs.mat, Tvec, parms.guess,statio=0){#
#
	tt  <- Tvec-Tvec[1];#
	q   <- length(tt) -1; #
	qp1 <- q+1;#
#
	if(statio==1){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4])) #
		optim.out <- optim(par=parms.guess,fn=joint.negloglike.OU, method="Nelder-Mead",Yobs.mat=Yobs.mat,tt=tt,statio=1)#
		mles <- c(optim.out$par[1], exp(optim.out$par[2:4]))#
		lnL.hat <- - optim.out$value[1]#
		AIC     <- -2*lnL.hat + 2*4 #where 4 = length(mles)... #
	}else if(statio==0){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4]), Yobs[1]);#
		optim.out <- optim(par=parms.guess, fn=joint.megloglike.OU, method="Nelder-Mead", Yobs.mat=Yobs.mat, tt=tt,statio=0);#
		mles      <- c(optim.out$par[1], exp(optim.out$par[2:5]));#
		lnL.hat   <- - optim.out$value[1]#
		AIC       <- -2*lnL.hat + 2*5 # where 5= length(mles) #
	}#
	out <- list(mles=mles, lnL.hat = lnL.hat, AIC=AIC)#
	return(out)#
}
joint.negloglike.OU <- function(fguess,Yobs.mat,tt,statio=0){#
	nts <- ncol(Yobs.mat);#
	nllikes <- rep(0,nts);#
		for(i in 1:nts){#
			Yobs <- Yobs.mat[,i]#
			nllikes[i] <- negloglike.OU.ml2(fguess=fguess,yt=Yobs,tt=tt,statio=statio)#
		}#
	return(sum(nnlikes))#
}
trial.block <- JOINT.ROUSS.ML(Yobs.mat=log(Host.dat), Tvec=Host.times, parms.guess=trial.one, statio=0)
trial.block <- JOINT.ROUSS.ML(Yobs.mat=log(Host.dat), Tvec=Host.times, parms.guess=guess.one, statio=0)
log(Host.dat)
Host.times
JOINT.ROUSS.ML(Yobs.mat=log(Host.dat), Tvec=Host.times, parms.guess=guess.one, statio=0)
JOINT.ROUSS.ML <- function(Yobs.mat, Tvec, parms.guess,statio=0){#
#
	tt  <- Tvec-Tvec[1];#
	q   <- length(tt) -1; #
	qp1 <- q+1;#
#
	if(statio==1){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4])) #
		optim.out <- optim(par=parms.guess,fn=joint.negloglike.OU, method="Nelder-Mead",Yobs.mat=Yobs.mat,tt=tt,statio=1)#
		mles <- c(optim.out$par[1], exp(optim.out$par[2:4]))#
		lnL.hat <- - optim.out$value[1]#
		AIC     <- -2*lnL.hat + 2*4 #where 4 = length(mles)... #
	}else if(statio==0){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4]), Yobs.mat[1,1]);#
		optim.out <- optim(par=parms.guess, fn=joint.megloglike.OU, method="Nelder-Mead", Yobs.mat=Yobs.mat, tt=tt,statio=0);#
		mles      <- c(optim.out$par[1], exp(optim.out$par[2:5]));#
		lnL.hat   <- - optim.out$value[1]#
		AIC       <- -2*lnL.hat + 2*5 # where 5= length(mles) #
	}#
	out <- list(mles=mles, lnL.hat = lnL.hat, AIC=AIC)#
	return(out)#
}
trial.block <- JOINT.ROUSS.ML(Yobs.mat=log(Host.dat), Tvec=Host.times, parms.guess=guess.one, statio=0)
JOINT.ROUSS.ML <- function(Yobs.mat, Tvec, parms.guess,statio=0){#
#
	tt  <- Tvec-Tvec[1];#
	q   <- length(tt) -1; #
	qp1 <- q+1;#
#
	if(statio==1){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4])) #
		optim.out <- optim(par=parms.guess,fn=joint.negloglike.OU, method="Nelder-Mead",Yobs.mat=Yobs.mat,tt=tt,statio=1)#
		mles <- c(optim.out$par[1], exp(optim.out$par[2:4]))#
		lnL.hat <- - optim.out$value[1]#
		AIC     <- -2*lnL.hat + 2*4 #where 4 = length(mles)... #
	}else if(statio==0){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4]), Yobs.mat[1,1]);#
		optim.out <- optim(par=parms.guess, fn=joint.negloglike.OU, method="Nelder-Mead", Yobs.mat=Yobs.mat, tt=tt,statio=0);#
		mles      <- c(optim.out$par[1], exp(optim.out$par[2:5]));#
		lnL.hat   <- - optim.out$value[1]#
		AIC       <- -2*lnL.hat + 2*5 # where 5= length(mles) #
	}#
	out <- list(mles=mles, lnL.hat = lnL.hat, AIC=AIC)#
	return(out)#
}
trial.block <- JOINT.ROUSS.ML(Yobs.mat=log(Host.dat), Tvec=Host.times, parms.guess=guess.one, statio=0)
joint.negloglike.OU <- function(fguess,Yobs.mat,tt,statio=0){#
	nts <- ncol(Yobs.mat);#
	nllikes <- rep(0,nts);#
		for(i in 1:nts){#
			Yobs <- Yobs.mat[,i]#
			nllikes[i] <- negloglike.OU.ml2(fguess=fguess,yt=Yobs,tt=tt,statio=statio)#
		}#
	return(sum(nllikes))#
}
trial.block <- JOINT.ROUSS.ML(Yobs.mat=log(Host.dat), Tvec=Host.times, parms.guess=guess.one, statio=0)
guess.one
Yobs.mat[1,1]
log(Host.dat)[1,1]
guess.one  <- guess.calc(Yobs=trial.onets, Tvec=Host.times);
trial.one  <- ROUSS.ML2(Yobs=trial.onets,Tvec=Host.times, parms.guess=guess.one, statio=0)
trial.one
ROUSS.ML2 <- function(Yobs,Tvec, parms.guess,statio=0){#
	tt  <- Tvec-Tvec[1];#
	q   <- length(tt) -1; #
	qp1 <- q+1;#
	if(statio==1){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4])) #
		optim.out <- optim(par=guess.optim,fn=negloglike.OU.ml,method="Nelder-Mead",yt=Yobs,tt=tt)#
		mles <- c(optim.out$par[1], exp(optim.out$par[2:4]))#
		lnL.hat <- - optim.out$value[1]#
		AIC     <- -2*lnL.hat + 2*4 #where 4 = length(mles)... #
	}else if(statio==0){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4]), Yobs[1]);#
		optim.out <- optim(par=guess.optim, fn=negloglike.OU.ml2, method="Nelder-Mead", yt=Yobs, tt=tt,statio=statio);#
		mles      <- c(optim.out$par[1], exp(optim.out$par[2:5]));#
		lnL.hat   <- - optim.out$value[1]#
		AIC       <- -2*lnL.hat + 2*5 # where 5= length(mles) #
	}#
	out <- list(mles=mles, lnL.hat = lnL.hat, AIC=AIC)#
	return(out)#
}
trial.one  <- ROUSS.ML2(Yobs=trial.onets,Tvec=Host.times, parms.guess=guess.one, statio=0)
trial.one
guess.one
JOINT.ROUSS.ML <- function(Yobs.mat, Tvec, parms.guess,statio=0){#
#
	tt  <- Tvec-Tvec[1];#
	q   <- length(tt) -1; #
	qp1 <- q+1;#
#
	if(statio==1){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4])) #
		optim.out <- optim(par=parms.guess,fn=joint.negloglike.OU, method="Nelder-Mead",Yobs.mat=Yobs.mat,tt=tt,statio=1)#
		mles <- c(optim.out$par[1], exp(optim.out$par[2:4]))#
		lnL.hat <- - optim.out$value[1]#
		AIC     <- -2*lnL.hat + 2*4 #where 4 = length(mles)... #
	}else if(statio==0){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4]), exp(Yobs.mat[1,1]));#
		optim.out <- optim(par=parms.guess, fn=joint.negloglike.OU, method="Nelder-Mead", Yobs.mat=Yobs.mat, tt=tt,statio=0);#
		mles      <- c(optim.out$par[1], exp(optim.out$par[2:5]));#
		lnL.hat   <- - optim.out$value[1]#
		AIC       <- -2*lnL.hat + 2*5 # where 5= length(mles) #
	}#
	out <- list(mles=mles, lnL.hat = lnL.hat, AIC=AIC)#
	return(out)#
}
trial.block <- JOINT.ROUSS.ML(Yobs.mat=log(Host.dat), Tvec=Host.times, parms.guess=guess.one, statio=0)
Yobs.mat=log(Host.dat)
Tvec=Host.times
parms.guess=guess.one
statio=0
JOINT.ROUSS.ML <- function(Yobs.mat, Tvec, parms.guess,statio=0){#
#
	tt  <- Tvec-Tvec[1];#
	q   <- length(tt) -1; #
	qp1 <- q+1;#
#
	if(statio==1){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4])) #
		optim.out <- optim(par=guess.optim,fn=joint.negloglike.OU, method="Nelder-Mead",Yobs.mat=Yobs.mat,tt=tt,statio=1)#
		mles <- c(optim.out$par[1], exp(optim.out$par[2:4]))#
		lnL.hat <- - optim.out$value[1]#
		AIC     <- -2*lnL.hat + 2*4 #where 4 = length(mles)... #
	}else if(statio==0){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4]), Yobs.mat[1,1]);#
		optim.out <- optim(par=guess.optim, fn=joint.negloglike.OU, method="Nelder-Mead", Yobs.mat=Yobs.mat, tt=tt,statio=0);#
		mles      <- c(optim.out$par[1], exp(optim.out$par[2:5]));#
		lnL.hat   <- - optim.out$value[1]#
		AIC       <- -2*lnL.hat + 2*5 # where 5= length(mles) #
	}#
	out <- list(mles=mles, lnL.hat = lnL.hat, AIC=AIC)#
	return(out)#
}
trial.block <- JOINT.ROUSS.ML(Yobs.mat=log(Host.dat), Tvec=Host.times, parms.guess=guess.one, statio=0)
trial.block
exp(trial.block$mles[1])
Host.dat
matplot(Host.dat, type="l",col=colors[1:11])
colors
colors()
colors()[1:11]
matplot(Host.dat, type="l",col=colors()[1:11])
negloglike.OU.ml2 <- function(fguess,yt,tt,statio=1){#
	# if statio=1, then use the stationary likelihood. else if statio = 0, use the nonstationary case#
	if(statio==1){#
		mu <- exp(fguess[1]);#
		guess  <- exp(fguess[2:4]); # Constrains parameters > 0#
		theta  <- guess[1]; #
		betasq <- guess[2];#
		tausq  <- guess[3];#
		q      <- length(yt) - 1;#
		qp1    <- q+1;#
		Var.inf<- betasq/(2*theta); # Better than Dr. Seuss' thing 1 and thing 2!#
		ss <- tt[2:qp1] - tt[1:q];#
		t.cols     <- matrix(rep(tt,each=qp1),nrow=qp1,ncol=qp1, byrow=FALSE);#
		t.rows     <- t(t.cols);#
		abs.diffs  <- abs(t.rows-t.cols);#
		V          <- Var.inf*exp(-theta*abs.diffs);#
		diag(V)    <- diag(V) + rep(tausq,qp1);#
		mu.vec     <- rep(mu,qp1);#
		neglogl <- (qp1/2)*log(2*pi)+(1/2)*log(det(V))+ (1/2)*(yt-mu.vec)%*%ginv(V)%*%(yt-mu.vec);#
	}else if(statio==0){#
		mu <- exp(fguess[1]);#
		guess  <- exp(fguess[2:5]); # Constrains parameters > 0#
		theta  <- guess[1]; #
		betasq <- guess[2];#
		tausq  <- guess[3];#
		xo     <- guess[4];	#
		q      <- length(yt) - 1;#
		qp1    <- q+1;#
		Var.inf<- betasq/(2*theta); # Better than Dr. Seuss' thing 1 and thing 2!#
		ss <- tt[2:qp1] - tt[1:q];#
		t.cols     <- matrix(rep(tt,each=qp1),nrow=qp1,ncol=qp1, byrow=FALSE);#
		t.rows     <- t(t.cols);#
		abs.diffs  <- abs(t.rows-t.cols);#
		min.titj   <- pmin(t.rows,t.cols); #elementwise minima between two matrices#
		V          <- Var.inf*(1-exp(-2*theta*min.titj))*exp(-theta*abs.diffs);#
		diag(V)    <- diag(V) + rep(tausq,qp1);#
		mu.vec     <- rep(mu,qp1) - (mu-xo)*exp(-theta*tt);#
		neglogl    <- (qp1/2)*log(2*pi)+(1/2)*log(det(V))+ (1/2)*(yt-mu.vec)%*%ginv(V)%*%(yt-mu.vec);#
	}#
	return(neglogl)#
}
ROUSS.ML2 <- function(Yobs,Tvec, parms.guess,statio=0){#
	tt  <- Tvec-Tvec[1];#
	q   <- length(tt) -1; #
	qp1 <- q+1;#
	if(statio==1){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4])) #
		optim.out <- optim(par=guess.optim,fn=negloglike.OU.ml,method="Nelder-Mead",yt=Yobs,tt=tt)#
		mles <- exp(optim.out$par)#
		lnL.hat <- - optim.out$value[1]#
		AIC     <- -2*lnL.hat + 2*4 #where 4 = length(mles)... #
	}else if(statio==0){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4]), Yobs[1]);#
		optim.out <- optim(par=guess.optim, fn=negloglike.OU.ml2, method="Nelder-Mead", yt=Yobs, tt=tt,statio=statio);#
		mles      <- exp(optim.out$par);#
		lnL.hat   <- - optim.out$value[1]#
		AIC       <- -2*lnL.hat + 2*5 # where 5= length(mles) #
	}#
	out <- list(mles=mles, lnL.hat = lnL.hat, AIC=AIC)#
	return(out)#
}
JOINT.ROUSS.ML <- function(Yobs.mat, Tvec, parms.guess,statio=0){#
#
	tt  <- Tvec-Tvec[1];#
	q   <- length(tt) -1; #
	qp1 <- q+1;#
#
	if(statio==1){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4])) #
		optim.out <- optim(par=guess.optim,fn=joint.negloglike.OU, method="Nelder-Mead",Yobs.mat=Yobs.mat,tt=tt,statio=1)#
		mles <- exp(optim.out$par)#
		lnL.hat <- - optim.out$value[1]#
		AIC     <- -2*lnL.hat + 2*4 #where 4 = length(mles)... #
	}else if(statio==0){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4]), Yobs.mat[1,1]);#
		optim.out <- optim(par=guess.optim, fn=joint.negloglike.OU, method="Nelder-Mead", Yobs.mat=Yobs.mat, tt=tt,statio=0);#
		mles      <- exp(optim.out$par);#
		lnL.hat   <- - optim.out$value[1]#
		AIC       <- -2*lnL.hat + 2*5 # where 5= length(mles) #
	}#
	out <- list(mles=mles, lnL.hat = lnL.hat, AIC=AIC)#
	return(out)#
}
trial.onets<- log(Host.dat[,1]);#
guess.one  <- guess.calc(Yobs=trial.onets, Tvec=Host.times);#
trial.one  <- ROUSS.ML2(Yobs=trial.onets,Tvec=Host.times, parms.guess=guess.one, statio=0)
trial.one
trial.block <- JOINT.ROUSS.ML(Yobs.mat=log(Host.dat), Tvec=Host.times, parms.guess=guess.one, statio=0)#
trial.block
JOINT.ROUSS.ML <- function(Yobs.mat, Tvec, parms.guess,statio=0){#
#
	tt  <- Tvec-Tvec[1];#
	q   <- length(tt) -1; #
	qp1 <- q+1;#
#
	if(statio==1){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4])) #
		optim.out <- optim(par=guess.optim,fn=joint.negloglike.OU, method="Nelder-Mead",Yobs.mat=Yobs.mat,tt=tt,statio=1)#
		mles <- c(optim.out$par[1],exp(optim.out$par[2:4]))#
		lnL.hat <- - optim.out$value[1]#
		AIC     <- -2*lnL.hat + 2*4 #where 4 = length(mles)... #
	}else if(statio==0){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4]), Yobs.mat[1,1]);#
		optim.out <- optim(par=guess.optim, fn=joint.negloglike.OU, method="Nelder-Mead", Yobs.mat=Yobs.mat, tt=tt,statio=0);#
		mles      <- c(optim.out$par[1],exp(optim.out$par[2:5]));#
		lnL.hat   <- - optim.out$value[1]#
		AIC       <- -2*lnL.hat + 2*5 # where 5= length(mles) #
	}#
	out <- list(mles=mles, lnL.hat = lnL.hat, AIC=AIC)#
	return(out)#
}
ROUSS.ML2 <- function(Yobs,Tvec, parms.guess,statio=0){#
	tt  <- Tvec-Tvec[1];#
	q   <- length(tt) -1; #
	qp1 <- q+1;#
	if(statio==1){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4])) #
		optim.out <- optim(par=guess.optim,fn=negloglike.OU.ml,method="Nelder-Mead",yt=Yobs,tt=tt)#
		mles <- c(optim.out$par[1], exp(optim.out$par[2:4]))#
		lnL.hat <- - optim.out$value[1]#
		AIC     <- -2*lnL.hat + 2*4 #where 4 = length(mles)... #
	}else if(statio==0){#
		guess.optim <- c(parms.guess[1], log(parms.guess[2:4]), Yobs[1]);#
		optim.out <- optim(par=guess.optim, fn=negloglike.OU.ml2, method="Nelder-Mead", yt=Yobs, tt=tt,statio=statio);#
		mles      <- c(optim.out$par[1], exp(optim.out$par[2:5]));#
		lnL.hat   <- - optim.out$value[1]#
		AIC       <- -2*lnL.hat + 2*5 # where 5= length(mles) #
	}#
	out <- list(mles=mles, lnL.hat = lnL.hat, AIC=AIC)#
	return(out)#
}
negloglike.OU.ml2 <- function(fguess,yt,tt,statio=1){#
	# if statio=1, then use the stationary likelihood. else if statio = 0, use the nonstationary case#
	if(statio==1){#
		mu <- fguess[1];#
		guess  <- exp(fguess[2:4]); # Constrains parameters > 0#
		theta  <- guess[1]; #
		betasq <- guess[2];#
		tausq  <- guess[3];#
		q      <- length(yt) - 1;#
		qp1    <- q+1;#
		Var.inf<- betasq/(2*theta); # Better than Dr. Seuss' thing 1 and thing 2!#
		ss <- tt[2:qp1] - tt[1:q];#
		t.cols     <- matrix(rep(tt,each=qp1),nrow=qp1,ncol=qp1, byrow=FALSE);#
		t.rows     <- t(t.cols);#
		abs.diffs  <- abs(t.rows-t.cols);#
		V          <- Var.inf*exp(-theta*abs.diffs);#
		diag(V)    <- diag(V) + rep(tausq,qp1);#
		mu.vec     <- rep(mu,qp1);#
		neglogl <- (qp1/2)*log(2*pi)+(1/2)*log(det(V))+ (1/2)*(yt-mu.vec)%*%ginv(V)%*%(yt-mu.vec);#
	}else if(statio==0){#
		mu <- fguess[1];#
		guess  <- exp(fguess[2:5]); # Constrains parameters > 0#
		theta  <- guess[1]; #
		betasq <- guess[2];#
		tausq  <- guess[3];#
		xo     <- guess[4];	#
		q      <- length(yt) - 1;#
		qp1    <- q+1;#
		Var.inf<- betasq/(2*theta); # Better than Dr. Seuss' thing 1 and thing 2!#
		ss <- tt[2:qp1] - tt[1:q];#
		t.cols     <- matrix(rep(tt,each=qp1),nrow=qp1,ncol=qp1, byrow=FALSE);#
		t.rows     <- t(t.cols);#
		abs.diffs  <- abs(t.rows-t.cols);#
		min.titj   <- pmin(t.rows,t.cols); #elementwise minima between two matrices#
		V          <- Var.inf*(1-exp(-2*theta*min.titj))*exp(-theta*abs.diffs);#
		diag(V)    <- diag(V) + rep(tausq,qp1);#
		mu.vec     <- rep(mu,qp1) - (mu-xo)*exp(-theta*tt);#
		neglogl    <- (qp1/2)*log(2*pi)+(1/2)*log(det(V))+ (1/2)*(yt-mu.vec)%*%ginv(V)%*%(yt-mu.vec);#
	}#
	return(neglogl)#
}
guess.one  <- guess.calc(Yobs=trial.onets, Tvec=Host.times);
trial.one  <- ROUSS.ML2(Yobs=trial.onets,Tvec=Host.times, parms.guess=guess.one, statio=0)
trial.one
length(trial.onets)
plot(1:100, trial.onets,type="l")
plot(1:100, trial.onets[1:100],type="l")
plot(1:100, exp(trial.onets[1:100]), type="l")
matplot(Host.dat[1:80,],type="l",col=colors()[11:21])
guess.one  <- guess.calc(Yobs=trial.onets[1:80], Tvec=Host.times[1:80]);#
trial.one  <- ROUSS.ML2(Yobs=trial.onets[1:80],Tvec=Host.times[1:80], parms.guess=guess.one, statio=0)
trial.one
Host.dat[,1]*100
Host.dat[,1]*1000
trial.onets<- log(Host.dat[,1]*1000);#
guess.one  <- guess.calc(Yobs=trial.onets[1:80], Tvec=Host.times[1:80]);#
trial.one  <- ROUSS.ML2(Yobs=trial.onets[1:80],Tvec=Host.times[1:80], parms.guess=guess.one, statio=0)
trial.one
trial.onets<- log(Host.dat[,1]*100);#
guess.one  <- guess.calc(Yobs=trial.onets[1:80], Tvec=Host.times[1:80]);#
trial.one  <- ROUSS.ML2(Yobs=trial.onets[1:80],Tvec=Host.times[1:80], parms.guess=guess.one, statio=0)#
trial.one
trial.onets<- log(Host.dat[,1]);#
guess.one  <- guess.calc(Yobs=trial.onets[1:80], Tvec=Host.times[1:80]);#
trial.one  <- ROUSS.ML2(Yobs=trial.onets[1:80],Tvec=Host.times[1:80], parms.guess=guess.one, statio=0)#
trial.one
mu.trial <- trial.one$mles[1]#
theta.trial <- trial.one$mles[2]#
betasq.trial <- trial.one$mles[3]#
tausq.trial <- trial.one$mles[4]#
xo.trial   <- trial.one$mles[5]
theta.trial
kappa.trial <- exp(mu.trial-(betasq.trial/(2*theta.trial)))
kappa.trial
plot(Host.dat[,1])
little.r <- theta.trial#
carrying.cap <- kappa.trial#
print(little.r, carrying.cap)
print(c(little.r, carrying.cap))
parms.trial <- c(theta.trial,kappa.trial)#
names(parms.trial) <- c("little r", "carrying capacity")#
print(parms.trial)
parms.trial <- c(theta.trial,kappa.trial)#
names(parms.trial) <- c("Little-r", "Carrying-capacity")#
print(parms.trial)
trial.block <- JOINT.ROUSS.ML(Yobs.mat=log(Host.dat), Tvec=Host.times, parms.guess=guess.one, statio=0)
trial.block
mu.trial2 <- trial.block$mles[1]#
theta.trial2 <- trial.block$mles[2]#
betasq.trial2 <- trial.block$mles[3]#
tausq.trial2 <- trial.block$mles[4]#
xo.trial2   <- trial.block$mles[5]#
kappa.trial2 <- exp(mu.trial2-(betasq.trial2/(2*theta.trial2)))#
#
# traditional little r and the carrying capacity:#
parms.trial2 <- c(theta.trial2,kappa.trial2)#
names(parms.trial2) <- c("Little-r", "Carrying-capacity")#
print(parms.trial2)
matplot(Host.dat, type="l", col=colors()[11:21])
n <- 500; # total number of samples#
hectares <- rnorm(n=n, mean= 600, sd= 200); # simulate a random sample of site sizes (in hectares)#
num.families <- sample(x=1:80, size=n, replace=TRUE, prob=(1:80)/80) # simulating the num. of families living in the plot
num.families
hectares
num.families <- sample(x=1:80, size=n, replace=TRUE, prob=(0:80)/81) # simulating the num. of families living in the plot
num.families <- sample(x=0:80, size=n, replace=TRUE, prob=(0:80)/81) # simulating the num. of families living in the plot
num.families
num.families <- sample(x=0:80, size=n, replace=TRUE, prob=(0:80)/81) # simulating the num. of families living in the plot
num.families
?cut
my.dataframe <- data.frame(1:n, hectares,num.families)
hectares
hist(hectares)
hectares <- rlnorm(n=n, meanlog= 600, sd= 200); # simulate a random sample of site sizes (in hectares)
hectares
hectares <- rlnorm(n=n, meanlog= 10, sd= 3); # simulate a random sample of site sizes (in hectares)
hectares
hectares <- rlnorm(n=n, meanlog= 5, sd= 2); # simulate a random sample of site sizes (in hectares)
hectares
hist(hectares)
hectares <- rlnorm(n=n, meanlog= 5, sd= 0.5); # simulate a random sample of site sizes (in hectares)
hist(hectares)
my.dataframe <- data.frame(1:n, hectares,num.families)
attach(my.dataframe)#
hectares.ints <- cut(hectares, breaks= c(50, 100,150,200,250,300,350,400,450))
hectares.ints
hectares
summary(hectares.ints)
?cut
hetaresf <- factor(hectares)
hectares.ints <- cut(hectaresf, breaks= c(50, 100,150,200,250,300,350,400,450))
hectares.ints <- cut(hetaresf, breaks= c(50, 100,150,200,250,300,350,400,450))
hectares[1:20]
hectares.ints <- cut(hectares[1:20], breaks= c(50, 100,150,200,250,300,350,400,450))
hectares.ints
?cut
hectares.ints <- cut(hectares[1:20], breaks= c(50, 100,150,200,250,300,350,400,450), dig.lab=2)
hectares.ints
hectares.ints <- cut(hectares[1:20], breaks= c(0,50, 100,150,200,250,300,350,400,450), dig.lab=2)
hectares.ints
hectares.ints <- cut(hectares, breaks= c(0,50, 100,150,200,250,300,350,400,450))
hectares.ints
summary(hectares.ints)
hectares[432]
hectares.ints <- cut(hectares, breaks= c((min(hectares)-1),50, 100,150,200,250,300,350,400,450, (max(hectares)+1)))
summary(hectares.ints)
hectares[1:14]
hectares.ints[1:14]
fams.factor <- cut(num.families, breaks= c((min(num.families)-1),10,20,30,40,50,60,70,(max(num.families)+1)) )
fams.factor
summary(fams.factor)
alldata
joint.Host121
0.09084/0.6478
exp(1)
log(10)
log(8, base=10)
log(10^8, base=10)
library("MASS")#
source("ROUSSE-1.0.R")
Observed.t <- c(18,10,9,14,17,14,5,10,9,5,11,11,4,5,4,8,2,3,9,2,4,7,4,1,2,4,11,11,9,6);#
Time.t    <- c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29);
log.obs    <- log(Observed.t);
NBoot  <- 10;#
#
# 2. At what level alpha do you want to test the null hypothesis of density independence vs. density dependence?#
my.alpha <- 0.05;#
#
# 3. Do you want to plot the sampling distribution of the log likelihood ratio -2*ln[L(Ho/L(H1))]#
#
plot.it <- FALSE#
#
pblrt.trial <- PBLRT.ddpcont(B=NBoot, Yobs=log.obs, Tvec=Time.t, alpha=my.alpha, plot.PBLR=plot.it)
pblrt.trial$egssml
pblrt.trial$roussml
PBLRT.ddpcont
method <- "REML" # alternatively, set method <- "ML"#
#
# 2. Do you want to plot the predictions?#
pred.plot <- "TRUE" # Set it to "FALSE" if you do not want to plot the predictions
pboot.plot <- "TRUE" # Set it to "FALSE" if you do not want to plot the bootstrap distribution of the estimates
NBoot <- 10;
all.results <- ROUSS.CALCS(Yobs=log.obs,Tvec=Time.t, pmethod=method, nboot=NBoot, plot.pred=pred.plot, plot.bootdists = pboot.plot);
pred.plot <- "FALSE" # Set it to "FALSE" if you do not want to plot the predictions
all.results <- ROUSS.CALCS(Yobs=log.obs,Tvec=Time.t, pmethod=method, nboot=NBoot, plot.pred=pred.plot, plot.bootdists = pboot.plot);
X11()
quit()
library("MASS")#
source("ROUSSE-1.0.R")
Time.t <- c(1946,1947,1948,1949,1950,1954,1955,1956,1957,1958,1959,1960,1961,1963,1964,1965,1966,1967,1968,1975,1976,1977,1978,1979,1980,1981);#
Observed.t <- c(672,1028,538,566,300,400,400,400,400,300,250,450,450,13,23,23,2,400,20,389,537,983,1698,1132,1702,1031);
log.obs    <- log(Observed.t);
method <- "REML" # alternatively, set method <- "ML"
pred.plot <- "FALSE" # Set it to "FALSE" if you do not want to plot the predictions
pboot.plot <- "FALSE" # Set it to "FALSE" if you do not want to plot the bootstrap distribution of the estimates
NBoot <- 10; # 10 just to try, for formal results use 1000 or more
all.results <- ROUSS.CALCS(Yobs=log.obs,Tvec=Time.t, pmethod=method, nboot=NBoot, plot.pred=pred.plot, plot.bootdists = pboot.plot);
all.results
exp(-0.08558213)
exp(-3.314256e-08)
NBoot <- 1000
NBoot <- 100
all.results <- ROUSS.CALCS(Yobs=log.obs,Tvec=Time.t, pmethod=method, nboot=NBoot, plot.pred=pred.plot, plot.bootdists = pboot.plot);
all.results
NBoot <- 1000
all.results <- ROUSS.CALCS(Yobs=log.obs,Tvec=Time.t, pmethod=method, nboot=NBoot, plot.pred=pred.plot, plot.bootdists = pboot.plot);
all.results
exp(-2.700949e-08)
pred.plot <- "TRUE" # Set it to "FALSE" if you do not want to plot the predictions#
#
# 3. Do you want to plot the parametric bootstrap distribution of the estimates?#
pboot.plot <- "TRUE" # Set it to "FALSE" if you do not want to plot the bootstrap distribution of the estimates#
#
# 4. How many bootstrap replicates?#
NBoot <- 1000; # 10 just to try, for formal results use 1000 or more #
#-------------------------------------------------------------------------------------------------##
#  5. RUN THE FOLLOWING LINE OF CODE TO COMPUTE THE ESTIMATES, PREDICTIONS,#
#     AND RUN A PARAMETRIC BOOTSTRAP. THE USER DOES NOT NEED TO MODIFY THIS LINE OF CODE.#
#     THE OUTPUT OF THE FUNCTION 'ROUSS.CALCS' IS A LIST AND THE USER CAN RETRIEVE EACH OF THE   #
#     LIST ELEMENTS PRINTED AND SAVED IN THE OBJECT "all.results". #
#     THE 95% PARAMETRIC BOOTSTRAP FOR BOTH, THE PARAMETERS AND THE PREDICTIONS ARE COMPUTED #
#     BY THE FUNCTION "ROUSS.CALCS" 	#
#      #
#-------------------------------------------------------------------------------------------------##
#
all.results <- ROUSS.CALCS(Yobs=log.obs,Tvec=Time.t, pmethod=method, nboot=NBoot, plot.pred=pred.plot, plot.bootdists = pboot.plot);
